version: '3.9'
services:
  # Contenedor Zookeeper: Es un servicio de coordinacion distribuida que Kafka utiliza para gestionar el cluster de brokers.
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes  # Permite conexiones sin autenticacion
    ports:
      - "2181:2181"  # Puerto para comunicarse con Kafka
    networks:
      - kafka_network
    volumes:
      - zookeeper:/bitnami/zookeeper  # Persistencia de datos de Zookeeper

  # Contenedor Kafka: Es el broker que gestiona la mensajeria y la transmision de eventos en tiempo real.
  kafka1:
    image: bitnami/kafka:latest
    container_name: kafka1
    depends_on:
      - zookeeper  # Kafka no inicia hasta que Zookeeper este listo
    command: ["sh", "-c", "sleep 10 && /opt/bitnami/scripts/kafka/run.sh"] # Retrasa el arranque de Kafka
    ports:
      - "9092:9092"  # Puerto para conexiones internas
      - "29092:29092" # Puerto para conexiones externas
    environment:     
      KAFKA_BROKER_ID: 1  # Identificacion del broker
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  # Conexion con Zookeeper

      # Configuracion de los listeners (definen como Kafka acepta conexiones)
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092
      # - INTERNAL: Para conexiones internas dentro del contenedor
      # - EXTERNAL: Para conexiones externas fuera del contenedor

      #  Direcciones que Kafka anuncia a los clientes para conectarse
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:9092,EXTERNAL://${KAFKA_HOST_IP}:29092
      # - INTERNAL: Se usa dentro de la red de Docker con el nombre `kafka1`
      # - EXTERNAL: Se usa fuera de Docker con la IP de la maquina `KAFKA_HOST_IP`

      #  Define que protocolo usa cada listener (solo texto plano en este caso)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT

      # Listener usado para la comunicacion entre brokers
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      #  Configuracion de replicacion (para alta disponibilidad)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 # Replicas del topico __consumer_offsets
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2       # Replicas por defecto en nuevos topicos
      KAFKA_MIN_INSYNC_REPLICAS: 1              # Minimo de replicas sincronizadas antes de aceptar un mensaje
    networks:
      - kafka_network
    volumes:
      - kafka1_data:/bitnami/kafka  # Persistencia de datos de Kafka
      
  # Contenedor Kafka2: Es el broker que gestiona la mensajeria y la transmision de eventos en tiempo real.
  kafka2:
    image: bitnami/kafka:latest
    container_name: kafka2
    depends_on:
      - zookeeper  # Kafka no iniciara hasta que Zookeeper este listo
    command: ["sh", "-c", "sleep 10 && /opt/bitnami/scripts/kafka/run.sh"] # Retrasa el arranque de Kafka
    ports:
      - "9093:9093"  # Puerto para conexiones internas
      - "29093:29093" # Puerto para conexiones externas
    environment:
      KAFKA_BROKER_ID: 2 # Identificacion del broker
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 # Conexion con Zookeeper

      # Configuracion de los listeners (definen como Kafka acepta conexiones)
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:29093
      # - INTERNAL: Para conexiones internas dentro del contenedor
      # - EXTERNAL: Para conexiones externas fuera del contenedor

      # Direcciones que Kafka anuncia a los clientes para conectarse
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:9093,EXTERNAL://${KAFKA_HOST_IP}:29093
      # - INTERNAL: Se usa dentro de la red de Docker con el nombre `kafka2`
      # - EXTERNAL: Se usa fuera de Docker con la IP de la maquina `KAFKA_HOST_IP`

      # Define que protocolo usa cada listener (solo texto plano en este caso)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT

      # Listener usado para la comunicacion entre brokers
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # Configuracion de replicacion (para alta disponibilidad)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 # Replicas del topico __consumer_offsets
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2       # Replicas por defecto en nuevos topicos
      KAFKA_MIN_INSYNC_REPLICAS: 1              # Minimo de relicas sincronizadas antes de aceptar un mensaje    networks:
    networks:
      - kafka_network
    volumes:
      - kafka2_data:/bitnami/kafka  # Persistencia de datos de Kafka

  # Contenedor Kafka-UI: Es una interfaz web para visualizar y gestionar Kafka.
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"  # Puerto para acceder a la interfaz web
    environment:
      KAFKA_CLUSTERS_0_NAME: local  # Nombre del cluster en la interfaz
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092,kafka2:9093  # Direccion de los broker de Kafka
    depends_on:
      - kafka1  # Espera a que Kafka este disponible antes de iniciar
      - kafka2  # Espera a que Kafka este disponible antes de iniciar
    networks:
      - kafka_network
    volumes:
      - kafka-ui-data:/config  # Persistencia de la configuracion de la interfaz

  # Contenedor POSTGRES
  postgres:
    image: postgres:14.4
    container_name: postgresKafka
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${SPRING_DATASOURCE_USERNAME}
      POSTGRES_PASSWORD: ${SPRING_DATASOURCE_PASSWORD}
    volumes:
      - postgres:/var/lib/postgresql/data
    networks:
      - kafka_network

#contendor de la aplicacion
  app:
    build: #  Define como se construye la imagen del contenedor.
      context: . # Usa el directorio actual como contexto de construccion.
      dockerfile: DockerfIle # Especifica el archivo Dockerfile a utilizar
    container_name: producerKafka
    depends_on:
      - postgres
      - kafka1
      - kafka2      
    env_file: # Carga variables de entorno desde un archivo .env
      - .env
    environment: # Define variables de entorno utilizadas por la aplicación Spring Boot.
      SPRING_KAFKA_BOOTSTRAP_SERVERS: ${SPRING_KAFKA_BOOTSTRAP_SERVERS} #  Lista de brokers de Kafka a los que se conecta.
      SPRING_DATASOURCE_URL: ${SPRING_DATASOURCE_URL} # URL de conexión a la base de datos.
      SPRING_DATASOURCE_USERNAME: ${SPRING_DATASOURCE_USERNAME} # Usuario de la base de datos.
      SPRING_DATASOURCE_PASSWORD: ${SPRING_DATASOURCE_PASSWORD} # Contraseña de la base de datos.
    ports:
      - 8081:8081
    networks:
      - kafka_network
  

# Red personalizada para la comunicacion entre contenedores
networks:
  kafka_network:
    driver: bridge  

# Volumenes para la persistencia de datos
volumes:
  zookeeper:
  kafka1_data:
  kafka2_data:
  kafka-ui-data:
  postgres:
